{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8cb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e860f12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhchung/dyngraph-uda/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72e5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88b8f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_nc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61fe5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad8ffd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585e964",
   "metadata": {},
   "source": [
    "## Model Structure ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa5669cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerGraphSAGE(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.conv1 = SAGEConv(in_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        return x\n",
    "    \n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.linear1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=self.dropout)\n",
    "        x = self.linear2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a4884",
   "metadata": {},
   "source": [
    "## Data Preparation ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3195bdf",
   "metadata": {},
   "source": [
    "* Train: 0-6\n",
    "* Val: 7, 8\n",
    "* Test: 9-13, 14-18, 19-23, 24-28, 29-33, 34-38, 39-43, 44-48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3f3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, dataset, sub_dataset=None):\n",
    "    if dataset == 'elliptic':\n",
    "        data = load_nc_dataset(data_dir, 'elliptic', sub_dataset)\n",
    "    else:\n",
    "        raise ValueError('Invalid dataname')\n",
    "    # if len(data.y.shape) == 1:\n",
    "    #     data.y = data.y.unsqueeze(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e2e981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/hhchung/data/graph-data/elliptic_bitcoin_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca0a5c",
   "metadata": {},
   "source": [
    "## Train / Test Loop ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a89c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, mlp, optimizer, loader, loss_fn):\n",
    "    encoder.train()\n",
    "    mlp.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    total_train_loss = 0\n",
    "    for data in loader:\n",
    "        out = mlp(encoder(data.x, data.edge_index))\n",
    "        loss = loss_fn(out[data.mask], data.y[data.mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    total_train_loss /= len(loader)\n",
    "    return total_train_loss\n",
    "    \n",
    "@torch.no_grad()\n",
    "def test(encoder, mlp, loader, loss_fn):\n",
    "    encoder.eval()\n",
    "    mlp.eval()\n",
    "    total_val_loss = 0\n",
    "    total_f1 = 0\n",
    "    for data in loader:\n",
    "        out = mlp(encoder(data.x, data.edge_index))\n",
    "        loss = loss_fn(out[data.mask], data.y[data.mask])\n",
    "        y_pred = torch.argmax(out, dim=1)\n",
    "        f1 = f1_score(y_pred[data.mask].detach().cpu().numpy(), data.y[data.mask].detach().cpu().numpy())\n",
    "        total_val_loss += loss.item()\n",
    "        total_f1 += f1\n",
    "    total_val_loss /= len(loader)\n",
    "    total_f1 /= len(loader)\n",
    "    return total_val_loss, total_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598cced",
   "metadata": {},
   "source": [
    "## Initial Source Stage ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d96f484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hhchung/dyngraph-uda/elliptic/dataset.py:75: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  edge_index = torch.tensor(A.nonzero(), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "elliptic_0 = get_data(data_dir, 'elliptic', 0)\n",
    "feat_dim = elliptic_0.x.shape[1]\n",
    "hidden_dim = 128\n",
    "emb_dim = 128\n",
    "encoder = TwoLayerGraphSAGE(feat_dim, hidden_dim, emb_dim)\n",
    "mlp = MLPHead(emb_dim, emb_dim // 4, 2)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(mlp.parameters()), lr=1e-3)\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c2f7706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = [0,7,9]\n",
    "train_data = [get_data(data_dir, 'elliptic', i) for i in range(split[0],split[1])]\n",
    "val_data = [get_data(data_dir, 'elliptic', i) for i in range(split[1],split[2])]\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7671fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/500 Train Loss:0.5299 Val Loss:0.5552 Val F1:0.0\n",
      "Epoch:2/500 Train Loss:0.3753 Val Loss:0.511 Val F1:0.004\n",
      "Epoch:3/500 Train Loss:0.3427 Val Loss:0.5046 Val F1:0.004\n",
      "Epoch:4/500 Train Loss:0.3369 Val Loss:0.5053 Val F1:0.004\n",
      "Epoch:5/500 Train Loss:0.3359 Val Loss:0.5024 Val F1:0.0\n",
      "Epoch:6/500 Train Loss:0.3355 Val Loss:0.5022 Val F1:0.0\n",
      "Epoch:7/500 Train Loss:0.3354 Val Loss:0.5016 Val F1:0.004\n",
      "Epoch:8/500 Train Loss:0.3352 Val Loss:0.5018 Val F1:0.0\n",
      "Epoch:9/500 Train Loss:0.3352 Val Loss:0.5017 Val F1:0.004\n",
      "Epoch:10/500 Train Loss:0.3351 Val Loss:0.5015 Val F1:0.004\n",
      "Epoch:11/500 Train Loss:0.3352 Val Loss:0.5012 Val F1:0.004\n",
      "Epoch:12/500 Train Loss:0.335 Val Loss:0.501 Val F1:0.0187\n",
      "Epoch:13/500 Train Loss:0.335 Val Loss:0.5013 Val F1:0.004\n",
      "Epoch:14/500 Train Loss:0.3349 Val Loss:0.501 Val F1:0.004\n",
      "Epoch:15/500 Train Loss:0.3348 Val Loss:0.501 Val F1:0.004\n",
      "Epoch:16/500 Train Loss:0.3348 Val Loss:0.5012 Val F1:0.004\n",
      "Epoch:17/500 Train Loss:0.3348 Val Loss:0.5012 Val F1:0.004\n",
      "Epoch:18/500 Train Loss:0.3348 Val Loss:0.5011 Val F1:0.004\n",
      "Epoch:19/500 Train Loss:0.3348 Val Loss:0.5011 Val F1:0.004\n",
      "Epoch:20/500 Train Loss:0.3347 Val Loss:0.5009 Val F1:0.004\n",
      "Epoch:21/500 Train Loss:0.3347 Val Loss:0.501 Val F1:0.004\n",
      "Epoch:22/500 Train Loss:0.3347 Val Loss:0.5011 Val F1:0.004\n",
      "Epoch:23/500 Train Loss:0.3345 Val Loss:0.5005 Val F1:0.0187\n",
      "Epoch:24/500 Train Loss:0.3345 Val Loss:0.5 Val F1:0.0187\n",
      "Epoch:25/500 Train Loss:0.3344 Val Loss:0.5001 Val F1:0.0187\n",
      "Epoch:26/500 Train Loss:0.3342 Val Loss:0.4997 Val F1:0.0187\n",
      "Epoch:27/500 Train Loss:0.3341 Val Loss:0.499 Val F1:0.0227\n",
      "Epoch:28/500 Train Loss:0.3337 Val Loss:0.4976 Val F1:0.0587\n",
      "Epoch:29/500 Train Loss:0.3336 Val Loss:0.4977 Val F1:0.0657\n",
      "Epoch:30/500 Train Loss:0.3335 Val Loss:0.4977 Val F1:0.0613\n",
      "Epoch:31/500 Train Loss:0.3333 Val Loss:0.4971 Val F1:0.0601\n",
      "Epoch:32/500 Train Loss:0.3333 Val Loss:0.4969 Val F1:0.0633\n",
      "Epoch:33/500 Train Loss:0.3332 Val Loss:0.4945 Val F1:0.0986\n",
      "Epoch:34/500 Train Loss:0.3328 Val Loss:0.4916 Val F1:0.1262\n",
      "Epoch:35/500 Train Loss:0.3327 Val Loss:0.4904 Val F1:0.145\n",
      "Epoch:36/500 Train Loss:0.3326 Val Loss:0.4902 Val F1:0.141\n",
      "Epoch:37/500 Train Loss:0.3326 Val Loss:0.4892 Val F1:0.1515\n",
      "Epoch:38/500 Train Loss:0.3325 Val Loss:0.4871 Val F1:0.1652\n",
      "Epoch:39/500 Train Loss:0.3324 Val Loss:0.4805 Val F1:0.2245\n",
      "Epoch:40/500 Train Loss:0.3323 Val Loss:0.4757 Val F1:0.2559\n",
      "Epoch:41/500 Train Loss:0.3319 Val Loss:0.4675 Val F1:0.2884\n",
      "Epoch:42/500 Train Loss:0.3318 Val Loss:0.4619 Val F1:0.3452\n",
      "Epoch:43/500 Train Loss:0.3312 Val Loss:0.4504 Val F1:0.4239\n",
      "Epoch:44/500 Train Loss:0.3312 Val Loss:0.4487 Val F1:0.4404\n",
      "Epoch:45/500 Train Loss:0.3308 Val Loss:0.4518 Val F1:0.4108\n",
      "Epoch:46/500 Train Loss:0.3307 Val Loss:0.4474 Val F1:0.4208\n",
      "Epoch:47/500 Train Loss:0.3306 Val Loss:0.4369 Val F1:0.5184\n",
      "Epoch:48/500 Train Loss:0.3304 Val Loss:0.4359 Val F1:0.5087\n",
      "Epoch:49/500 Train Loss:0.3301 Val Loss:0.4384 Val F1:0.4747\n",
      "Epoch:50/500 Train Loss:0.3301 Val Loss:0.4263 Val F1:0.553\n",
      "Epoch:51/500 Train Loss:0.3318 Val Loss:0.4166 Val F1:0.6489\n",
      "Epoch:52/500 Train Loss:0.331 Val Loss:0.4348 Val F1:0.493\n",
      "Epoch:53/500 Train Loss:0.331 Val Loss:0.4653 Val F1:0.2664\n",
      "Epoch:54/500 Train Loss:0.3319 Val Loss:0.4528 Val F1:0.3462\n",
      "Epoch:55/500 Train Loss:0.3313 Val Loss:0.4363 Val F1:0.4677\n",
      "Epoch:56/500 Train Loss:0.3307 Val Loss:0.4291 Val F1:0.5372\n",
      "Epoch:57/500 Train Loss:0.3303 Val Loss:0.4234 Val F1:0.5853\n",
      "Epoch:58/500 Train Loss:0.329 Val Loss:0.4126 Val F1:0.6358\n",
      "Epoch:59/500 Train Loss:0.3286 Val Loss:0.4004 Val F1:0.6784\n",
      "Epoch:60/500 Train Loss:0.3282 Val Loss:0.4122 Val F1:0.6078\n",
      "Epoch:61/500 Train Loss:0.3314 Val Loss:0.4571 Val F1:0.3186\n",
      "Epoch:62/500 Train Loss:0.332 Val Loss:0.4549 Val F1:0.3445\n",
      "Epoch:63/500 Train Loss:0.3308 Val Loss:0.4387 Val F1:0.4673\n",
      "Epoch:64/500 Train Loss:0.33 Val Loss:0.4205 Val F1:0.5543\n",
      "Epoch:65/500 Train Loss:0.3272 Val Loss:0.4004 Val F1:0.6691\n",
      "Epoch:66/500 Train Loss:0.3283 Val Loss:0.3947 Val F1:0.6771\n",
      "Epoch:67/500 Train Loss:0.3281 Val Loss:0.4187 Val F1:0.5331\n",
      "Epoch:68/500 Train Loss:0.3289 Val Loss:0.4112 Val F1:0.5802\n",
      "Epoch:69/500 Train Loss:0.3274 Val Loss:0.3939 Val F1:0.7021\n",
      "Epoch:70/500 Train Loss:0.3308 Val Loss:0.3918 Val F1:0.6926\n",
      "Epoch:71/500 Train Loss:0.3249 Val Loss:0.405 Val F1:0.5935\n",
      "Epoch:72/500 Train Loss:0.3279 Val Loss:0.4023 Val F1:0.6184\n",
      "Epoch:73/500 Train Loss:0.326 Val Loss:0.3855 Val F1:0.7173\n",
      "Epoch:74/500 Train Loss:0.3272 Val Loss:0.3865 Val F1:0.7327\n",
      "Epoch:75/500 Train Loss:0.3249 Val Loss:0.3929 Val F1:0.6595\n",
      "Epoch:76/500 Train Loss:0.3246 Val Loss:0.4063 Val F1:0.5939\n",
      "Epoch:77/500 Train Loss:0.3254 Val Loss:0.3854 Val F1:0.7036\n",
      "Epoch:78/500 Train Loss:0.3252 Val Loss:0.376 Val F1:0.7752\n",
      "Epoch:79/500 Train Loss:0.3239 Val Loss:0.3755 Val F1:0.7467\n",
      "Epoch:80/500 Train Loss:0.3242 Val Loss:0.379 Val F1:0.6941\n",
      "Epoch:81/500 Train Loss:0.3237 Val Loss:0.372 Val F1:0.7299\n",
      "Epoch:82/500 Train Loss:0.3232 Val Loss:0.3688 Val F1:0.7387\n",
      "Epoch:83/500 Train Loss:0.3224 Val Loss:0.3684 Val F1:0.7658\n",
      "Epoch:84/500 Train Loss:0.3219 Val Loss:0.3718 Val F1:0.7475\n",
      "Epoch:85/500 Train Loss:0.3217 Val Loss:0.3824 Val F1:0.701\n",
      "Epoch:86/500 Train Loss:0.3218 Val Loss:0.3803 Val F1:0.716\n",
      "Epoch:87/500 Train Loss:0.3213 Val Loss:0.3765 Val F1:0.726\n",
      "Epoch:88/500 Train Loss:0.3212 Val Loss:0.3761 Val F1:0.7217\n",
      "Epoch:89/500 Train Loss:0.3211 Val Loss:0.3768 Val F1:0.7156\n",
      "Epoch:90/500 Train Loss:0.3212 Val Loss:0.3772 Val F1:0.712\n",
      "Epoch:91/500 Train Loss:0.3212 Val Loss:0.3735 Val F1:0.742\n",
      "Epoch:92/500 Train Loss:0.3209 Val Loss:0.3722 Val F1:0.7478\n",
      "Epoch:93/500 Train Loss:0.3209 Val Loss:0.3729 Val F1:0.7433\n",
      "Epoch:94/500 Train Loss:0.321 Val Loss:0.3763 Val F1:0.7288\n",
      "Epoch:95/500 Train Loss:0.3207 Val Loss:0.3744 Val F1:0.7384\n",
      "Epoch:96/500 Train Loss:0.3207 Val Loss:0.3771 Val F1:0.7188\n",
      "Epoch:97/500 Train Loss:0.3204 Val Loss:0.3742 Val F1:0.7465\n",
      "Epoch:98/500 Train Loss:0.3206 Val Loss:0.3739 Val F1:0.7505\n",
      "Epoch:99/500 Train Loss:0.3209 Val Loss:0.3757 Val F1:0.7366\n",
      "Epoch:100/500 Train Loss:0.3212 Val Loss:0.3729 Val F1:0.7374\n",
      "Epoch:101/500 Train Loss:0.3211 Val Loss:0.3749 Val F1:0.739\n",
      "Epoch:102/500 Train Loss:0.3212 Val Loss:0.3725 Val F1:0.7536\n",
      "Epoch:103/500 Train Loss:0.3212 Val Loss:0.3674 Val F1:0.7756\n",
      "Epoch:104/500 Train Loss:0.3209 Val Loss:0.3701 Val F1:0.7398\n",
      "Epoch:105/500 Train Loss:0.3213 Val Loss:0.3743 Val F1:0.7045\n",
      "Epoch:106/500 Train Loss:0.3213 Val Loss:0.3742 Val F1:0.6953\n",
      "Epoch:107/500 Train Loss:0.3213 Val Loss:0.3731 Val F1:0.7573\n",
      "Epoch:108/500 Train Loss:0.3218 Val Loss:0.3725 Val F1:0.7557\n",
      "Epoch:109/500 Train Loss:0.3206 Val Loss:0.3708 Val F1:0.7458\n",
      "Epoch:110/500 Train Loss:0.3207 Val Loss:0.3733 Val F1:0.7377\n",
      "Epoch:111/500 Train Loss:0.3203 Val Loss:0.3749 Val F1:0.7431\n",
      "Epoch:112/500 Train Loss:0.3202 Val Loss:0.3744 Val F1:0.7383\n",
      "Epoch:113/500 Train Loss:0.3208 Val Loss:0.3757 Val F1:0.72\n",
      "Epoch:114/500 Train Loss:0.3206 Val Loss:0.3742 Val F1:0.7359\n",
      "Epoch:115/500 Train Loss:0.3204 Val Loss:0.375 Val F1:0.7485\n",
      "Epoch:116/500 Train Loss:0.3205 Val Loss:0.3723 Val F1:0.7645\n",
      "Epoch:117/500 Train Loss:0.3199 Val Loss:0.3679 Val F1:0.7806\n",
      "Epoch:118/500 Train Loss:0.32 Val Loss:0.3676 Val F1:0.7719\n",
      "Epoch:119/500 Train Loss:0.3201 Val Loss:0.3721 Val F1:0.754\n",
      "Epoch:120/500 Train Loss:0.3205 Val Loss:0.3741 Val F1:0.743\n",
      "Epoch:121/500 Train Loss:0.3203 Val Loss:0.3746 Val F1:0.7185\n",
      "Epoch:122/500 Train Loss:0.3207 Val Loss:0.3786 Val F1:0.6927\n",
      "Epoch:123/500 Train Loss:0.3203 Val Loss:0.3718 Val F1:0.7385\n",
      "Epoch:124/500 Train Loss:0.3203 Val Loss:0.3723 Val F1:0.7696\n",
      "Epoch:125/500 Train Loss:0.3202 Val Loss:0.3767 Val F1:0.7475\n",
      "Epoch:126/500 Train Loss:0.32 Val Loss:0.3753 Val F1:0.7143\n",
      "Epoch:127/500 Train Loss:0.3201 Val Loss:0.3747 Val F1:0.7309\n",
      "Epoch:128/500 Train Loss:0.32 Val Loss:0.3729 Val F1:0.7457\n",
      "Epoch:129/500 Train Loss:0.32 Val Loss:0.3713 Val F1:0.7613\n",
      "Epoch:130/500 Train Loss:0.32 Val Loss:0.3729 Val F1:0.7312\n",
      "Epoch:131/500 Train Loss:0.3199 Val Loss:0.3708 Val F1:0.7666\n",
      "Epoch:132/500 Train Loss:0.3199 Val Loss:0.3737 Val F1:0.7429\n",
      "Epoch:133/500 Train Loss:0.3201 Val Loss:0.3728 Val F1:0.7619\n",
      "Epoch:134/500 Train Loss:0.3198 Val Loss:0.3703 Val F1:0.7717\n",
      "Epoch:135/500 Train Loss:0.3197 Val Loss:0.37 Val F1:0.7509\n",
      "Epoch:136/500 Train Loss:0.3198 Val Loss:0.3697 Val F1:0.7519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:137/500 Train Loss:0.3198 Val Loss:0.3701 Val F1:0.7353\n",
      "Epoch:138/500 Train Loss:0.3198 Val Loss:0.3721 Val F1:0.7335\n",
      "Epoch:139/500 Train Loss:0.3198 Val Loss:0.3688 Val F1:0.7649\n",
      "Epoch:140/500 Train Loss:0.3197 Val Loss:0.3674 Val F1:0.7825\n",
      "Epoch:141/500 Train Loss:0.3197 Val Loss:0.3691 Val F1:0.7462\n",
      "Epoch:142/500 Train Loss:0.3198 Val Loss:0.3735 Val F1:0.7499\n",
      "Epoch:143/500 Train Loss:0.3198 Val Loss:0.3679 Val F1:0.7722\n",
      "Epoch:144/500 Train Loss:0.3199 Val Loss:0.3708 Val F1:0.7577\n",
      "Epoch:145/500 Train Loss:0.3198 Val Loss:0.3735 Val F1:0.7402\n",
      "Epoch:146/500 Train Loss:0.3196 Val Loss:0.3729 Val F1:0.7446\n",
      "Epoch:147/500 Train Loss:0.3196 Val Loss:0.3744 Val F1:0.7371\n",
      "Epoch:148/500 Train Loss:0.3197 Val Loss:0.3729 Val F1:0.7347\n",
      "Epoch:149/500 Train Loss:0.3199 Val Loss:0.3725 Val F1:0.7509\n",
      "Epoch:150/500 Train Loss:0.3196 Val Loss:0.3718 Val F1:0.7481\n",
      "Epoch:151/500 Train Loss:0.3198 Val Loss:0.3693 Val F1:0.7765\n",
      "Epoch:152/500 Train Loss:0.3196 Val Loss:0.371 Val F1:0.7572\n",
      "Epoch:153/500 Train Loss:0.3196 Val Loss:0.3728 Val F1:0.7668\n",
      "Epoch:154/500 Train Loss:0.3196 Val Loss:0.3722 Val F1:0.7654\n",
      "Epoch:155/500 Train Loss:0.3196 Val Loss:0.3737 Val F1:0.7309\n",
      "Epoch:156/500 Train Loss:0.3197 Val Loss:0.373 Val F1:0.7374\n",
      "Epoch:157/500 Train Loss:0.3197 Val Loss:0.3698 Val F1:0.7669\n",
      "Epoch:158/500 Train Loss:0.3196 Val Loss:0.3675 Val F1:0.7854\n",
      "Epoch:159/500 Train Loss:0.3197 Val Loss:0.3706 Val F1:0.7511\n",
      "Epoch:160/500 Train Loss:0.3197 Val Loss:0.3705 Val F1:0.7417\n",
      "Epoch:161/500 Train Loss:0.3197 Val Loss:0.3705 Val F1:0.7722\n",
      "Epoch:162/500 Train Loss:0.3199 Val Loss:0.3703 Val F1:0.7761\n",
      "Epoch:163/500 Train Loss:0.3197 Val Loss:0.3716 Val F1:0.7616\n",
      "Epoch:164/500 Train Loss:0.3198 Val Loss:0.3724 Val F1:0.7476\n",
      "Epoch:165/500 Train Loss:0.3206 Val Loss:0.3766 Val F1:0.7489\n",
      "Epoch:166/500 Train Loss:0.3207 Val Loss:0.3695 Val F1:0.7755\n",
      "Epoch:167/500 Train Loss:0.3199 Val Loss:0.3683 Val F1:0.7689\n",
      "Epoch:168/500 Train Loss:0.3198 Val Loss:0.3698 Val F1:0.7613\n",
      "Epoch:169/500 Train Loss:0.32 Val Loss:0.3656 Val F1:0.7853\n",
      "Epoch:170/500 Train Loss:0.3208 Val Loss:0.3669 Val F1:0.7902\n",
      "Epoch:171/500 Train Loss:0.32 Val Loss:0.371 Val F1:0.7386\n",
      "Epoch:172/500 Train Loss:0.3214 Val Loss:0.3826 Val F1:0.7161\n",
      "Epoch:173/500 Train Loss:0.3205 Val Loss:0.3699 Val F1:0.7936\n",
      "Epoch:174/500 Train Loss:0.3228 Val Loss:0.3728 Val F1:0.7922\n",
      "Epoch:175/500 Train Loss:0.3204 Val Loss:0.3766 Val F1:0.7274\n",
      "Epoch:176/500 Train Loss:0.3212 Val Loss:0.3789 Val F1:0.7083\n",
      "Epoch:177/500 Train Loss:0.3203 Val Loss:0.3755 Val F1:0.7315\n",
      "Epoch:178/500 Train Loss:0.3202 Val Loss:0.3765 Val F1:0.7483\n",
      "Epoch:179/500 Train Loss:0.3201 Val Loss:0.37 Val F1:0.7837\n",
      "Epoch:180/500 Train Loss:0.3201 Val Loss:0.3762 Val F1:0.7364\n",
      "Epoch:181/500 Train Loss:0.3208 Val Loss:0.3761 Val F1:0.7326\n",
      "Epoch:182/500 Train Loss:0.3203 Val Loss:0.3756 Val F1:0.7632\n",
      "Epoch:183/500 Train Loss:0.3207 Val Loss:0.3743 Val F1:0.7599\n",
      "Epoch:184/500 Train Loss:0.3211 Val Loss:0.3785 Val F1:0.7222\n",
      "Epoch:185/500 Train Loss:0.3211 Val Loss:0.3748 Val F1:0.7334\n",
      "Epoch:186/500 Train Loss:0.3209 Val Loss:0.3705 Val F1:0.7588\n",
      "Epoch:187/500 Train Loss:0.32 Val Loss:0.3705 Val F1:0.751\n",
      "Epoch:188/500 Train Loss:0.3201 Val Loss:0.3742 Val F1:0.7035\n",
      "Epoch:189/500 Train Loss:0.3197 Val Loss:0.3733 Val F1:0.722\n",
      "Epoch:190/500 Train Loss:0.3197 Val Loss:0.3747 Val F1:0.7305\n",
      "Epoch:191/500 Train Loss:0.32 Val Loss:0.3726 Val F1:0.7436\n",
      "Epoch:192/500 Train Loss:0.3197 Val Loss:0.3693 Val F1:0.771\n",
      "Epoch:193/500 Train Loss:0.3196 Val Loss:0.3724 Val F1:0.7486\n",
      "Epoch:194/500 Train Loss:0.3199 Val Loss:0.3742 Val F1:0.7561\n",
      "Epoch:195/500 Train Loss:0.3195 Val Loss:0.3729 Val F1:0.733\n",
      "Epoch:196/500 Train Loss:0.3195 Val Loss:0.37 Val F1:0.7485\n",
      "Epoch:197/500 Train Loss:0.3196 Val Loss:0.376 Val F1:0.7233\n",
      "Epoch:198/500 Train Loss:0.3197 Val Loss:0.3725 Val F1:0.7448\n",
      "Epoch:199/500 Train Loss:0.3195 Val Loss:0.366 Val F1:0.7794\n",
      "Epoch:200/500 Train Loss:0.3195 Val Loss:0.3666 Val F1:0.7636\n",
      "Epoch:201/500 Train Loss:0.3198 Val Loss:0.3653 Val F1:0.7645\n",
      "Epoch:202/500 Train Loss:0.3196 Val Loss:0.3715 Val F1:0.7465\n",
      "Epoch:203/500 Train Loss:0.3196 Val Loss:0.373 Val F1:0.7435\n",
      "Epoch:204/500 Train Loss:0.3196 Val Loss:0.3685 Val F1:0.7829\n",
      "Epoch:205/500 Train Loss:0.3195 Val Loss:0.3737 Val F1:0.7578\n",
      "Epoch:206/500 Train Loss:0.3196 Val Loss:0.3688 Val F1:0.7507\n",
      "Epoch:207/500 Train Loss:0.3196 Val Loss:0.3695 Val F1:0.7565\n",
      "Epoch:208/500 Train Loss:0.3195 Val Loss:0.3725 Val F1:0.7199\n",
      "Epoch:209/500 Train Loss:0.3198 Val Loss:0.3714 Val F1:0.7308\n",
      "Epoch:210/500 Train Loss:0.3199 Val Loss:0.3695 Val F1:0.7451\n",
      "Epoch:211/500 Train Loss:0.3195 Val Loss:0.3668 Val F1:0.78\n",
      "Epoch:212/500 Train Loss:0.3197 Val Loss:0.3662 Val F1:0.773\n",
      "Epoch:213/500 Train Loss:0.3195 Val Loss:0.368 Val F1:0.7837\n",
      "Epoch:214/500 Train Loss:0.3194 Val Loss:0.3699 Val F1:0.7463\n",
      "Epoch:215/500 Train Loss:0.3195 Val Loss:0.3676 Val F1:0.7758\n",
      "Epoch:216/500 Train Loss:0.3195 Val Loss:0.3706 Val F1:0.7617\n",
      "Epoch:217/500 Train Loss:0.3195 Val Loss:0.365 Val F1:0.7925\n",
      "Epoch:218/500 Train Loss:0.3196 Val Loss:0.3647 Val F1:0.7912\n",
      "Epoch:219/500 Train Loss:0.3197 Val Loss:0.3661 Val F1:0.763\n",
      "Epoch:220/500 Train Loss:0.321 Val Loss:0.3713 Val F1:0.726\n",
      "Epoch:221/500 Train Loss:0.3202 Val Loss:0.3685 Val F1:0.7445\n",
      "Epoch:222/500 Train Loss:0.3202 Val Loss:0.3648 Val F1:0.7904\n",
      "Epoch:223/500 Train Loss:0.3195 Val Loss:0.3624 Val F1:0.7812\n",
      "Epoch:224/500 Train Loss:0.3195 Val Loss:0.3638 Val F1:0.7817\n",
      "Epoch:225/500 Train Loss:0.3196 Val Loss:0.3671 Val F1:0.7698\n",
      "Epoch:226/500 Train Loss:0.3194 Val Loss:0.3661 Val F1:0.7788\n",
      "Epoch:227/500 Train Loss:0.3195 Val Loss:0.366 Val F1:0.7706\n",
      "Epoch:228/500 Train Loss:0.3194 Val Loss:0.3713 Val F1:0.7597\n",
      "Epoch:229/500 Train Loss:0.3193 Val Loss:0.3646 Val F1:0.783\n",
      "Epoch:230/500 Train Loss:0.3194 Val Loss:0.3665 Val F1:0.7751\n",
      "Epoch:231/500 Train Loss:0.3196 Val Loss:0.3692 Val F1:0.78\n",
      "Epoch:232/500 Train Loss:0.3194 Val Loss:0.3665 Val F1:0.7926\n",
      "Epoch:233/500 Train Loss:0.3195 Val Loss:0.3664 Val F1:0.7805\n",
      "Epoch:234/500 Train Loss:0.3194 Val Loss:0.3723 Val F1:0.7365\n",
      "Epoch:235/500 Train Loss:0.3194 Val Loss:0.3685 Val F1:0.7644\n",
      "Epoch:236/500 Train Loss:0.3196 Val Loss:0.3674 Val F1:0.7625\n",
      "Epoch:237/500 Train Loss:0.3193 Val Loss:0.3679 Val F1:0.7604\n",
      "Epoch:238/500 Train Loss:0.3193 Val Loss:0.3707 Val F1:0.7487\n",
      "Epoch:239/500 Train Loss:0.3195 Val Loss:0.3712 Val F1:0.7498\n",
      "Epoch:240/500 Train Loss:0.3193 Val Loss:0.3691 Val F1:0.7499\n",
      "Epoch:241/500 Train Loss:0.3195 Val Loss:0.37 Val F1:0.7438\n",
      "Epoch:242/500 Train Loss:0.3193 Val Loss:0.3689 Val F1:0.7398\n",
      "Epoch:243/500 Train Loss:0.3194 Val Loss:0.3718 Val F1:0.7264\n",
      "Epoch:244/500 Train Loss:0.3194 Val Loss:0.3683 Val F1:0.7672\n",
      "Epoch:245/500 Train Loss:0.3193 Val Loss:0.368 Val F1:0.7524\n",
      "Epoch:246/500 Train Loss:0.3193 Val Loss:0.3668 Val F1:0.7585\n",
      "Epoch:247/500 Train Loss:0.3193 Val Loss:0.3697 Val F1:0.7696\n",
      "Epoch:248/500 Train Loss:0.3195 Val Loss:0.366 Val F1:0.7564\n",
      "Epoch:249/500 Train Loss:0.3195 Val Loss:0.3743 Val F1:0.7192\n",
      "Epoch:250/500 Train Loss:0.32 Val Loss:0.3714 Val F1:0.7396\n",
      "Epoch:251/500 Train Loss:0.3193 Val Loss:0.3696 Val F1:0.7749\n",
      "Epoch:252/500 Train Loss:0.3193 Val Loss:0.3665 Val F1:0.7861\n",
      "Epoch:253/500 Train Loss:0.3193 Val Loss:0.3632 Val F1:0.781\n",
      "Epoch:254/500 Train Loss:0.3194 Val Loss:0.3682 Val F1:0.772\n",
      "Epoch:255/500 Train Loss:0.3196 Val Loss:0.3701 Val F1:0.7295\n",
      "Epoch:256/500 Train Loss:0.3197 Val Loss:0.3694 Val F1:0.7432\n",
      "Epoch:257/500 Train Loss:0.3194 Val Loss:0.367 Val F1:0.7748\n",
      "Epoch:258/500 Train Loss:0.3196 Val Loss:0.366 Val F1:0.806\n",
      "Epoch:259/500 Train Loss:0.3194 Val Loss:0.3661 Val F1:0.7548\n",
      "Epoch:260/500 Train Loss:0.32 Val Loss:0.3742 Val F1:0.7326\n",
      "Epoch:261/500 Train Loss:0.3195 Val Loss:0.3673 Val F1:0.7742\n",
      "Epoch:262/500 Train Loss:0.3193 Val Loss:0.3678 Val F1:0.7898\n",
      "Epoch:263/500 Train Loss:0.3193 Val Loss:0.3663 Val F1:0.7762\n",
      "Epoch:264/500 Train Loss:0.3192 Val Loss:0.3654 Val F1:0.7598\n",
      "Epoch:265/500 Train Loss:0.3193 Val Loss:0.367 Val F1:0.7742\n",
      "Epoch:266/500 Train Loss:0.3194 Val Loss:0.3658 Val F1:0.7532\n",
      "Epoch:267/500 Train Loss:0.3193 Val Loss:0.3711 Val F1:0.7397\n",
      "Epoch:268/500 Train Loss:0.3195 Val Loss:0.3641 Val F1:0.7745\n",
      "Epoch:269/500 Train Loss:0.3195 Val Loss:0.3673 Val F1:0.7769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:270/500 Train Loss:0.3196 Val Loss:0.3704 Val F1:0.7515\n",
      "Epoch:271/500 Train Loss:0.3195 Val Loss:0.3689 Val F1:0.7724\n",
      "Epoch:272/500 Train Loss:0.3195 Val Loss:0.3658 Val F1:0.789\n",
      "Epoch:273/500 Train Loss:0.3195 Val Loss:0.3698 Val F1:0.7728\n",
      "Epoch:274/500 Train Loss:0.32 Val Loss:0.3648 Val F1:0.7931\n",
      "Epoch:275/500 Train Loss:0.3195 Val Loss:0.3726 Val F1:0.7514\n",
      "Epoch:276/500 Train Loss:0.3198 Val Loss:0.3691 Val F1:0.7685\n",
      "Epoch:277/500 Train Loss:0.3193 Val Loss:0.3713 Val F1:0.7813\n",
      "Epoch:278/500 Train Loss:0.3197 Val Loss:0.3651 Val F1:0.7925\n",
      "Epoch:279/500 Train Loss:0.3194 Val Loss:0.3623 Val F1:0.7829\n",
      "Epoch:280/500 Train Loss:0.3194 Val Loss:0.3649 Val F1:0.772\n",
      "Epoch:281/500 Train Loss:0.3192 Val Loss:0.364 Val F1:0.769\n",
      "Epoch:282/500 Train Loss:0.3192 Val Loss:0.3688 Val F1:0.7573\n",
      "Epoch:283/500 Train Loss:0.3192 Val Loss:0.3678 Val F1:0.7413\n",
      "Epoch:284/500 Train Loss:0.3192 Val Loss:0.364 Val F1:0.7629\n",
      "Epoch:285/500 Train Loss:0.3191 Val Loss:0.3622 Val F1:0.784\n",
      "Epoch:286/500 Train Loss:0.3191 Val Loss:0.3648 Val F1:0.7678\n",
      "Epoch:287/500 Train Loss:0.3191 Val Loss:0.3645 Val F1:0.7848\n",
      "Epoch:288/500 Train Loss:0.3191 Val Loss:0.3625 Val F1:0.7854\n",
      "Epoch:289/500 Train Loss:0.3191 Val Loss:0.3619 Val F1:0.7925\n",
      "Epoch:290/500 Train Loss:0.3191 Val Loss:0.3623 Val F1:0.7766\n",
      "Epoch:291/500 Train Loss:0.3191 Val Loss:0.3634 Val F1:0.7811\n",
      "Epoch:292/500 Train Loss:0.3192 Val Loss:0.3644 Val F1:0.7584\n",
      "Epoch:293/500 Train Loss:0.3191 Val Loss:0.3658 Val F1:0.7646\n",
      "Epoch:294/500 Train Loss:0.3191 Val Loss:0.3624 Val F1:0.7859\n",
      "Epoch:295/500 Train Loss:0.3191 Val Loss:0.3654 Val F1:0.7855\n",
      "Epoch:296/500 Train Loss:0.3191 Val Loss:0.3646 Val F1:0.7707\n",
      "Epoch:297/500 Train Loss:0.3192 Val Loss:0.3599 Val F1:0.7893\n",
      "Epoch:298/500 Train Loss:0.3191 Val Loss:0.3637 Val F1:0.7902\n",
      "Epoch:299/500 Train Loss:0.3192 Val Loss:0.3629 Val F1:0.784\n",
      "Epoch:300/500 Train Loss:0.3192 Val Loss:0.3647 Val F1:0.7828\n",
      "Epoch:301/500 Train Loss:0.3191 Val Loss:0.3621 Val F1:0.7647\n",
      "Epoch:302/500 Train Loss:0.3191 Val Loss:0.3624 Val F1:0.7744\n",
      "Epoch:303/500 Train Loss:0.3191 Val Loss:0.3689 Val F1:0.7345\n",
      "Epoch:304/500 Train Loss:0.3191 Val Loss:0.3652 Val F1:0.7656\n",
      "Epoch:305/500 Train Loss:0.3191 Val Loss:0.3612 Val F1:0.7802\n",
      "Epoch:306/500 Train Loss:0.3191 Val Loss:0.3624 Val F1:0.7742\n",
      "Epoch:307/500 Train Loss:0.3193 Val Loss:0.3649 Val F1:0.7776\n",
      "Epoch:308/500 Train Loss:0.3191 Val Loss:0.3619 Val F1:0.7866\n",
      "Epoch:309/500 Train Loss:0.3191 Val Loss:0.3618 Val F1:0.79\n",
      "Epoch:310/500 Train Loss:0.3192 Val Loss:0.3653 Val F1:0.7747\n",
      "Epoch:311/500 Train Loss:0.3192 Val Loss:0.3674 Val F1:0.7372\n",
      "Epoch:312/500 Train Loss:0.3192 Val Loss:0.3682 Val F1:0.7506\n",
      "Epoch:313/500 Train Loss:0.3191 Val Loss:0.366 Val F1:0.7623\n",
      "Epoch:314/500 Train Loss:0.3193 Val Loss:0.364 Val F1:0.7672\n",
      "Epoch:315/500 Train Loss:0.3192 Val Loss:0.3647 Val F1:0.7486\n",
      "Epoch:316/500 Train Loss:0.3193 Val Loss:0.3647 Val F1:0.7404\n",
      "Epoch:317/500 Train Loss:0.3193 Val Loss:0.3626 Val F1:0.7574\n",
      "Epoch:318/500 Train Loss:0.3191 Val Loss:0.3615 Val F1:0.7786\n",
      "Epoch:319/500 Train Loss:0.3194 Val Loss:0.3592 Val F1:0.8002\n",
      "Epoch:320/500 Train Loss:0.3191 Val Loss:0.3704 Val F1:0.7545\n",
      "Epoch:321/500 Train Loss:0.3201 Val Loss:0.3684 Val F1:0.7825\n",
      "Epoch:322/500 Train Loss:0.3197 Val Loss:0.3677 Val F1:0.7886\n",
      "Epoch:323/500 Train Loss:0.3195 Val Loss:0.3664 Val F1:0.7699\n",
      "Epoch:324/500 Train Loss:0.3195 Val Loss:0.3666 Val F1:0.7808\n",
      "Epoch:325/500 Train Loss:0.3192 Val Loss:0.3632 Val F1:0.8051\n",
      "Epoch:326/500 Train Loss:0.3194 Val Loss:0.3662 Val F1:0.7988\n",
      "Epoch:327/500 Train Loss:0.3196 Val Loss:0.3648 Val F1:0.797\n",
      "Epoch:328/500 Train Loss:0.3193 Val Loss:0.371 Val F1:0.7546\n",
      "Epoch:329/500 Train Loss:0.3198 Val Loss:0.3682 Val F1:0.7731\n",
      "Epoch:330/500 Train Loss:0.3195 Val Loss:0.3664 Val F1:0.7948\n",
      "Epoch:331/500 Train Loss:0.3198 Val Loss:0.3693 Val F1:0.7922\n",
      "Epoch:332/500 Train Loss:0.32 Val Loss:0.3673 Val F1:0.7758\n",
      "Epoch:333/500 Train Loss:0.3195 Val Loss:0.3659 Val F1:0.7624\n",
      "Epoch:334/500 Train Loss:0.3192 Val Loss:0.369 Val F1:0.7525\n",
      "Epoch:335/500 Train Loss:0.3191 Val Loss:0.3685 Val F1:0.756\n",
      "Epoch:336/500 Train Loss:0.3191 Val Loss:0.364 Val F1:0.7891\n",
      "Epoch:337/500 Train Loss:0.3191 Val Loss:0.3682 Val F1:0.7608\n",
      "Epoch:338/500 Train Loss:0.3192 Val Loss:0.3678 Val F1:0.7711\n",
      "Epoch:339/500 Train Loss:0.3193 Val Loss:0.3679 Val F1:0.7744\n",
      "Epoch:340/500 Train Loss:0.3192 Val Loss:0.367 Val F1:0.7899\n",
      "Epoch:341/500 Train Loss:0.3192 Val Loss:0.3665 Val F1:0.7647\n",
      "Epoch:342/500 Train Loss:0.3191 Val Loss:0.3721 Val F1:0.7244\n",
      "Epoch:343/500 Train Loss:0.3193 Val Loss:0.3699 Val F1:0.738\n",
      "Epoch:344/500 Train Loss:0.3192 Val Loss:0.3637 Val F1:0.7849\n",
      "Epoch:345/500 Train Loss:0.3195 Val Loss:0.3609 Val F1:0.7999\n",
      "Epoch:346/500 Train Loss:0.3193 Val Loss:0.3631 Val F1:0.7814\n",
      "Epoch:347/500 Train Loss:0.3192 Val Loss:0.3644 Val F1:0.7749\n",
      "Epoch:348/500 Train Loss:0.3193 Val Loss:0.3629 Val F1:0.7881\n",
      "Epoch:349/500 Train Loss:0.3192 Val Loss:0.3622 Val F1:0.8114\n",
      "Epoch:350/500 Train Loss:0.3192 Val Loss:0.3657 Val F1:0.7733\n",
      "Epoch:351/500 Train Loss:0.3192 Val Loss:0.3654 Val F1:0.7769\n",
      "Epoch:352/500 Train Loss:0.3191 Val Loss:0.3644 Val F1:0.7768\n",
      "Epoch:353/500 Train Loss:0.3193 Val Loss:0.3634 Val F1:0.7756\n",
      "Epoch:354/500 Train Loss:0.3193 Val Loss:0.3609 Val F1:0.7946\n",
      "Epoch:355/500 Train Loss:0.3192 Val Loss:0.3639 Val F1:0.7929\n",
      "Epoch:356/500 Train Loss:0.3193 Val Loss:0.3595 Val F1:0.8048\n",
      "Epoch:357/500 Train Loss:0.3192 Val Loss:0.3612 Val F1:0.7936\n",
      "Epoch:358/500 Train Loss:0.3193 Val Loss:0.3594 Val F1:0.785\n",
      "Epoch:359/500 Train Loss:0.3192 Val Loss:0.3666 Val F1:0.747\n",
      "Epoch:360/500 Train Loss:0.3192 Val Loss:0.3674 Val F1:0.7463\n",
      "Epoch:361/500 Train Loss:0.3191 Val Loss:0.3682 Val F1:0.7356\n",
      "Epoch:362/500 Train Loss:0.3192 Val Loss:0.3657 Val F1:0.7683\n",
      "Epoch:363/500 Train Loss:0.3192 Val Loss:0.3656 Val F1:0.7483\n",
      "Epoch:364/500 Train Loss:0.3191 Val Loss:0.3657 Val F1:0.766\n",
      "Epoch:365/500 Train Loss:0.3191 Val Loss:0.3657 Val F1:0.7555\n",
      "Epoch:366/500 Train Loss:0.3191 Val Loss:0.3647 Val F1:0.7712\n",
      "Epoch:367/500 Train Loss:0.3191 Val Loss:0.3633 Val F1:0.7941\n",
      "Epoch:368/500 Train Loss:0.3193 Val Loss:0.3653 Val F1:0.7878\n",
      "Epoch:369/500 Train Loss:0.3194 Val Loss:0.3653 Val F1:0.7921\n",
      "Epoch:370/500 Train Loss:0.3191 Val Loss:0.3662 Val F1:0.7571\n",
      "Epoch:371/500 Train Loss:0.3194 Val Loss:0.3681 Val F1:0.7681\n",
      "Epoch:372/500 Train Loss:0.3193 Val Loss:0.3652 Val F1:0.7927\n",
      "Epoch:373/500 Train Loss:0.3191 Val Loss:0.3644 Val F1:0.7899\n",
      "Epoch:374/500 Train Loss:0.3192 Val Loss:0.3652 Val F1:0.7886\n",
      "Epoch:375/500 Train Loss:0.3191 Val Loss:0.3629 Val F1:0.7873\n",
      "Epoch:376/500 Train Loss:0.3191 Val Loss:0.363 Val F1:0.7875\n",
      "Epoch:377/500 Train Loss:0.3191 Val Loss:0.3592 Val F1:0.8005\n",
      "Epoch:378/500 Train Loss:0.3191 Val Loss:0.3593 Val F1:0.7974\n",
      "Epoch:379/500 Train Loss:0.3191 Val Loss:0.3595 Val F1:0.808\n",
      "Epoch:380/500 Train Loss:0.3191 Val Loss:0.3593 Val F1:0.7848\n",
      "Epoch:381/500 Train Loss:0.3191 Val Loss:0.3626 Val F1:0.7916\n",
      "Epoch:382/500 Train Loss:0.3191 Val Loss:0.3611 Val F1:0.7835\n",
      "Epoch:383/500 Train Loss:0.3191 Val Loss:0.3606 Val F1:0.7965\n",
      "Epoch:384/500 Train Loss:0.3191 Val Loss:0.3624 Val F1:0.7807\n",
      "Epoch:385/500 Train Loss:0.3191 Val Loss:0.3645 Val F1:0.789\n",
      "Epoch:386/500 Train Loss:0.3191 Val Loss:0.3584 Val F1:0.8205\n",
      "Epoch:387/500 Train Loss:0.3191 Val Loss:0.3564 Val F1:0.8128\n",
      "Epoch:388/500 Train Loss:0.3191 Val Loss:0.357 Val F1:0.8136\n",
      "Epoch:389/500 Train Loss:0.3191 Val Loss:0.3592 Val F1:0.7963\n",
      "Epoch:390/500 Train Loss:0.3191 Val Loss:0.3608 Val F1:0.7914\n",
      "Epoch:391/500 Train Loss:0.3191 Val Loss:0.3579 Val F1:0.8122\n",
      "Epoch:392/500 Train Loss:0.3192 Val Loss:0.3594 Val F1:0.7979\n",
      "Epoch:393/500 Train Loss:0.3191 Val Loss:0.3611 Val F1:0.7861\n",
      "Epoch:394/500 Train Loss:0.3191 Val Loss:0.3602 Val F1:0.8004\n",
      "Epoch:395/500 Train Loss:0.3191 Val Loss:0.3593 Val F1:0.8183\n",
      "Epoch:396/500 Train Loss:0.3191 Val Loss:0.3618 Val F1:0.7886\n",
      "Epoch:397/500 Train Loss:0.3191 Val Loss:0.3584 Val F1:0.8044\n",
      "Epoch:398/500 Train Loss:0.3191 Val Loss:0.3625 Val F1:0.797\n",
      "Epoch:399/500 Train Loss:0.3191 Val Loss:0.3615 Val F1:0.8006\n",
      "Epoch:400/500 Train Loss:0.3191 Val Loss:0.3636 Val F1:0.7823\n",
      "Epoch:401/500 Train Loss:0.3191 Val Loss:0.3609 Val F1:0.7882\n",
      "Epoch:402/500 Train Loss:0.3191 Val Loss:0.3609 Val F1:0.8076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:403/500 Train Loss:0.3191 Val Loss:0.3609 Val F1:0.7905\n",
      "Epoch:404/500 Train Loss:0.3191 Val Loss:0.3616 Val F1:0.7915\n",
      "Epoch:405/500 Train Loss:0.319 Val Loss:0.3613 Val F1:0.795\n",
      "Epoch:406/500 Train Loss:0.3192 Val Loss:0.3596 Val F1:0.792\n",
      "Epoch:407/500 Train Loss:0.3191 Val Loss:0.363 Val F1:0.7654\n",
      "Epoch:408/500 Train Loss:0.3194 Val Loss:0.3658 Val F1:0.7723\n",
      "Epoch:409/500 Train Loss:0.3192 Val Loss:0.36 Val F1:0.8051\n",
      "Epoch:410/500 Train Loss:0.3191 Val Loss:0.3624 Val F1:0.8083\n",
      "Epoch:411/500 Train Loss:0.3192 Val Loss:0.3596 Val F1:0.8072\n",
      "Epoch:412/500 Train Loss:0.3192 Val Loss:0.3576 Val F1:0.8109\n",
      "Epoch:413/500 Train Loss:0.319 Val Loss:0.3645 Val F1:0.7643\n",
      "Epoch:414/500 Train Loss:0.319 Val Loss:0.3686 Val F1:0.7558\n",
      "Epoch:415/500 Train Loss:0.319 Val Loss:0.3671 Val F1:0.7479\n",
      "Epoch:416/500 Train Loss:0.3191 Val Loss:0.3626 Val F1:0.7877\n",
      "Epoch:417/500 Train Loss:0.319 Val Loss:0.368 Val F1:0.7559\n",
      "Epoch:418/500 Train Loss:0.3192 Val Loss:0.3645 Val F1:0.7664\n",
      "Epoch:419/500 Train Loss:0.3192 Val Loss:0.3632 Val F1:0.7872\n",
      "Epoch:420/500 Train Loss:0.3191 Val Loss:0.366 Val F1:0.7945\n",
      "Epoch:421/500 Train Loss:0.319 Val Loss:0.3639 Val F1:0.7975\n",
      "Epoch:422/500 Train Loss:0.3191 Val Loss:0.3668 Val F1:0.7836\n",
      "Epoch:423/500 Train Loss:0.3191 Val Loss:0.3618 Val F1:0.7906\n",
      "Epoch:424/500 Train Loss:0.319 Val Loss:0.3623 Val F1:0.7953\n",
      "Epoch:425/500 Train Loss:0.319 Val Loss:0.3649 Val F1:0.7746\n",
      "Epoch:426/500 Train Loss:0.319 Val Loss:0.366 Val F1:0.7837\n",
      "Epoch:427/500 Train Loss:0.3191 Val Loss:0.3619 Val F1:0.7978\n",
      "Epoch:428/500 Train Loss:0.3203 Val Loss:0.3618 Val F1:0.7796\n",
      "Epoch:429/500 Train Loss:0.3196 Val Loss:0.3811 Val F1:0.702\n",
      "Epoch:430/500 Train Loss:0.3205 Val Loss:0.3722 Val F1:0.7437\n",
      "Epoch:431/500 Train Loss:0.32 Val Loss:0.3647 Val F1:0.7973\n",
      "Epoch:432/500 Train Loss:0.321 Val Loss:0.3692 Val F1:0.7496\n",
      "Epoch:433/500 Train Loss:0.3205 Val Loss:0.393 Val F1:0.625\n",
      "Epoch:434/500 Train Loss:0.3216 Val Loss:0.3778 Val F1:0.7187\n",
      "Epoch:435/500 Train Loss:0.324 Val Loss:0.3785 Val F1:0.7406\n",
      "Epoch:436/500 Train Loss:0.321 Val Loss:0.3968 Val F1:0.6173\n",
      "Epoch:437/500 Train Loss:0.3248 Val Loss:0.3952 Val F1:0.6541\n",
      "Epoch:438/500 Train Loss:0.3225 Val Loss:0.3823 Val F1:0.7197\n",
      "Epoch:439/500 Train Loss:0.3242 Val Loss:0.3831 Val F1:0.7204\n",
      "Epoch:440/500 Train Loss:0.3222 Val Loss:0.3785 Val F1:0.7053\n",
      "Epoch:441/500 Train Loss:0.3216 Val Loss:0.3877 Val F1:0.6358\n",
      "Epoch:442/500 Train Loss:0.3213 Val Loss:0.3686 Val F1:0.7252\n",
      "Epoch:443/500 Train Loss:0.3198 Val Loss:0.3671 Val F1:0.7957\n",
      "Epoch:444/500 Train Loss:0.3209 Val Loss:0.369 Val F1:0.7573\n",
      "Epoch:445/500 Train Loss:0.3197 Val Loss:0.3712 Val F1:0.7299\n",
      "Epoch:446/500 Train Loss:0.3202 Val Loss:0.3693 Val F1:0.7665\n",
      "Epoch:447/500 Train Loss:0.3199 Val Loss:0.374 Val F1:0.7509\n",
      "Epoch:448/500 Train Loss:0.3199 Val Loss:0.3718 Val F1:0.7601\n",
      "Epoch:449/500 Train Loss:0.3196 Val Loss:0.3778 Val F1:0.7133\n",
      "Epoch:450/500 Train Loss:0.3197 Val Loss:0.3776 Val F1:0.7105\n",
      "Epoch:451/500 Train Loss:0.3197 Val Loss:0.3769 Val F1:0.7165\n",
      "Epoch:452/500 Train Loss:0.3194 Val Loss:0.372 Val F1:0.7498\n",
      "Epoch:453/500 Train Loss:0.3194 Val Loss:0.3739 Val F1:0.7386\n",
      "Epoch:454/500 Train Loss:0.3193 Val Loss:0.3667 Val F1:0.7817\n",
      "Epoch:455/500 Train Loss:0.3192 Val Loss:0.3657 Val F1:0.7699\n",
      "Epoch:456/500 Train Loss:0.3194 Val Loss:0.3674 Val F1:0.7819\n",
      "Epoch:457/500 Train Loss:0.3194 Val Loss:0.3658 Val F1:0.7649\n",
      "Epoch:458/500 Train Loss:0.3194 Val Loss:0.3713 Val F1:0.743\n",
      "Epoch:459/500 Train Loss:0.3195 Val Loss:0.3798 Val F1:0.7189\n",
      "Epoch:460/500 Train Loss:0.3199 Val Loss:0.3828 Val F1:0.6916\n",
      "Epoch:461/500 Train Loss:0.3197 Val Loss:0.3733 Val F1:0.7325\n",
      "Epoch:462/500 Train Loss:0.3201 Val Loss:0.3741 Val F1:0.7652\n",
      "Epoch:463/500 Train Loss:0.3192 Val Loss:0.3713 Val F1:0.7524\n",
      "Epoch:464/500 Train Loss:0.3194 Val Loss:0.3703 Val F1:0.729\n",
      "Epoch:465/500 Train Loss:0.3194 Val Loss:0.3696 Val F1:0.7249\n",
      "Epoch:466/500 Train Loss:0.319 Val Loss:0.3733 Val F1:0.7228\n",
      "Epoch:467/500 Train Loss:0.3191 Val Loss:0.3736 Val F1:0.7188\n",
      "Epoch:468/500 Train Loss:0.3191 Val Loss:0.3706 Val F1:0.7366\n",
      "Epoch:469/500 Train Loss:0.3189 Val Loss:0.3711 Val F1:0.7551\n",
      "Epoch:470/500 Train Loss:0.319 Val Loss:0.3713 Val F1:0.7432\n",
      "Epoch:471/500 Train Loss:0.3189 Val Loss:0.373 Val F1:0.7369\n",
      "Epoch:472/500 Train Loss:0.319 Val Loss:0.3726 Val F1:0.7269\n",
      "Epoch:473/500 Train Loss:0.3189 Val Loss:0.3747 Val F1:0.723\n",
      "Epoch:474/500 Train Loss:0.3189 Val Loss:0.3762 Val F1:0.7045\n",
      "Epoch:475/500 Train Loss:0.3189 Val Loss:0.3703 Val F1:0.7455\n",
      "Epoch:476/500 Train Loss:0.3189 Val Loss:0.3709 Val F1:0.736\n",
      "Epoch:477/500 Train Loss:0.319 Val Loss:0.3689 Val F1:0.7455\n",
      "Epoch:478/500 Train Loss:0.3189 Val Loss:0.3738 Val F1:0.7242\n",
      "Epoch:479/500 Train Loss:0.3189 Val Loss:0.3734 Val F1:0.7433\n",
      "Epoch:480/500 Train Loss:0.3189 Val Loss:0.3752 Val F1:0.7399\n",
      "Epoch:481/500 Train Loss:0.3189 Val Loss:0.372 Val F1:0.7459\n",
      "Epoch:482/500 Train Loss:0.3189 Val Loss:0.3742 Val F1:0.7128\n",
      "Epoch:483/500 Train Loss:0.3189 Val Loss:0.375 Val F1:0.7221\n",
      "Epoch:484/500 Train Loss:0.319 Val Loss:0.3727 Val F1:0.7319\n",
      "Epoch:485/500 Train Loss:0.3189 Val Loss:0.3736 Val F1:0.7123\n",
      "Epoch:486/500 Train Loss:0.3189 Val Loss:0.3745 Val F1:0.7323\n",
      "Epoch:487/500 Train Loss:0.3189 Val Loss:0.3738 Val F1:0.7356\n",
      "Epoch:488/500 Train Loss:0.3189 Val Loss:0.3749 Val F1:0.7305\n",
      "Epoch:489/500 Train Loss:0.3189 Val Loss:0.3758 Val F1:0.7283\n",
      "Epoch:490/500 Train Loss:0.3188 Val Loss:0.3758 Val F1:0.7152\n",
      "Epoch:491/500 Train Loss:0.3189 Val Loss:0.3738 Val F1:0.7257\n",
      "Epoch:492/500 Train Loss:0.3189 Val Loss:0.3726 Val F1:0.7574\n",
      "Epoch:493/500 Train Loss:0.3189 Val Loss:0.3751 Val F1:0.7137\n",
      "Epoch:494/500 Train Loss:0.3189 Val Loss:0.3743 Val F1:0.7298\n",
      "Epoch:495/500 Train Loss:0.3189 Val Loss:0.3726 Val F1:0.7267\n",
      "Epoch:496/500 Train Loss:0.3189 Val Loss:0.3748 Val F1:0.7273\n",
      "Epoch:497/500 Train Loss:0.3188 Val Loss:0.3725 Val F1:0.724\n",
      "Epoch:498/500 Train Loss:0.3188 Val Loss:0.3707 Val F1:0.7441\n",
      "Epoch:499/500 Train Loss:0.3188 Val Loss:0.3701 Val F1:0.7558\n",
      "Epoch:500/500 Train Loss:0.3188 Val Loss:0.3709 Val F1:0.7576\n"
     ]
    }
   ],
   "source": [
    "best_f1 = 0\n",
    "best_encoder = None\n",
    "best_mlp = None\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = train(encoder, mlp, optimizer, train_loader, loss_fn)\n",
    "    val_loss, val_f1 = test(encoder, mlp, val_loader, loss_fn)\n",
    "    print(f\"Epoch:{e}/{epochs} Train Loss:{round(train_loss,4)} Val Loss:{round(val_loss,4)} Val F1:{round(val_f1, 4)}\")\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_encoder = deepcopy(encoder)\n",
    "        best_mlp = deepcopy(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d8b5ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8204539239814055\n"
     ]
    }
   ],
   "source": [
    "print(best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea56b5",
   "metadata": {},
   "source": [
    "## Evaluation on Subsequent Time Steps ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a967c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "f1_list.append(best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903eab0d",
   "metadata": {},
   "source": [
    "### 9-13 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af0b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(9,14)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98177228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3671, Test F1: 0.6834\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db88096",
   "metadata": {},
   "source": [
    "### 14-18 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55243d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(14,19)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bfdc043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3861, Test F1: 0.7663\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fe1ff7",
   "metadata": {},
   "source": [
    "### 19-23 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7550e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(19,24)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea43f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4522, Test F1: 0.4956\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236f388",
   "metadata": {},
   "source": [
    "### 24-28 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cd2200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(24,29)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82862669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4782, Test F1: 0.6363\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df94c7",
   "metadata": {},
   "source": [
    "### 29-33 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4543d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(29,34)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "530a9b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6153, Test F1: 0.3815\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd1e7a",
   "metadata": {},
   "source": [
    "### 34-38 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4e83cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(34,39)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f318972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6339, Test F1: 0.3276\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdc8a9",
   "metadata": {},
   "source": [
    "### 39-43 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31c5db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(39,44)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d838a3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9014, Test F1: 0.1569\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d27ea87",
   "metadata": {},
   "source": [
    "### 44-48 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42abac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [get_data(data_dir, \"elliptic\", i) for i in range(44,49)]\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94b732a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6948, Test F1: 0.1666\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1 = test(encoder, mlp, test_loader, loss_fn)\n",
    "f1_list.append(test_f1)\n",
    "print(f\"Test Loss: {round(test_loss,4)}, Test F1: {round(test_f1,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742b342",
   "metadata": {},
   "source": [
    "* 9-13, 14-18, 19-23, 24-28, 29-33, 34-38, 39-43, 44-48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74820680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1, len(f1_list)+1)), f1_list)\n",
    "plt.title(\"Performance Degradation Over Time\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.xlabel(\"Evaluation Time Step\")\n",
    "plt.savefig(\"degradeelliptic.png\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c280f42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49274156669450275"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(f1_list) / len(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577b10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
